{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41341966-685e-48e7-aff0-bf378566fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "access_token = \"secret-token\"\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6bd451-73c8-4294-8a10-b8c304194378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel, TFBertForQuestionAnswering,TFAutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739e56b7-8939-46e3-8396-fb90e65fd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_use = 0\n",
    "st = \"cuda:\"+str(GPU_use)\n",
    "torch.cuda.set_device(GPU_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d58058-1799-4e3a-b21a-f0b0e6b4822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset('marcomaccarini/ds_robot_33_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de81cd7-01f5-4ce1-b7f0-13caade7a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ea47cc-323c-4c9f-a321-e06ac788a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [17:12<00:00, 258.01s/it]\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = 'meta-llama/Meta-Llama-3-8B'\n",
    "tokr = AutoTokenizer.from_pretrained(base_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"marcomaccarini/SynthLA\", torch_dtype=torch.bfloat16, device_map=GPU_use,token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8b26b7-9b4e-4dfd-9824-85aee170ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "USER: {}\n",
    "===\n",
    "{}\n",
    "ASSISTANT:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86ae860-deba-4ab1-b83e-fa63ed0117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_prompt(d): \n",
    "    return fmt.format(d[\"context\"], d[\"question\"])\n",
    "def question(table, quest):\n",
    "    tst = dict(**trn[8])\n",
    "    tst['context'] = table\n",
    "    tst['question'] = quest\n",
    "    return sql_prompt(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa218ef1-e92a-41b8-ad48-633a87d1d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = 'table([ eof x: 421 y: -115 z: 125, gripper: open , black-cup x: 321 y: 217 z: 80, green-cube x: 425 y: -120 z: 80 or: 14 ])'\n",
    "t = 'table([ eof x: 85 y: 179 z: 548, gripper: open , black-cup x: -54 y: -27 z: 80, white-cup x: -5 y: 59 z: 60, box x: -30 y: 34 z: 100, green-cylinder x: 25 y: -3 z: 80 or: 142, green-cube x: -390 y: -490 z: 80 or: 83, grey-cube x: 56 y: -22 z: 80 or: 96, red-cube x: -32 y: 58 z: 80 or: 157, yellow-ball x: -21 y: 30 z: 20 or: 41, banana x: 2 y: 53 z: 20 or: 9, remote x: -48 y: 31 z: 30 or: 69, pen x: -53 y: -59 z: 10 or: 174 ])'\n",
    "q = 'pick green-cube and place to black-cup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de063923-ffb0-478b-99df-014438d1c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 μs, sys: 0 ns, total: 17 μs\n",
      "Wall time: 32.4 μs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test = question(t,q)\n",
    "toks = tokr(test, return_tensors=\"pt\")\n",
    "res = model.generate(**toks.to(st), max_new_tokens=100, top_p = 0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943b5ec2-296e-4256-a883-7484744ed0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "USER: table([ eof x: 85 y: 179 z: 548, gripper: open, black-cup x: -54 y: -27 z: 80, white-cup x: -5 y: 59 z: 60, box x: -30 y: 34 z: 100, green-cylinder x: 25 y: -3 z: 80 or: 142, green-cube x: -390 y: -490 z: 80 or: 83, grey-cube x: 56 y: -22 z: 80 or: 96, red-cube x: -32 y: 58 z: 80 or: 157, yellow-ball x: -21 y: 30 z: 20 or: 41, banana x: 2 y: 53 z: 20 or: 9, remote x: -48 y: 31 z: 30 or: 69, pen x: -53 y: -59 z: 10 or: 174 ])\n",
      "===\n",
      "pick green-cube and place to black-cup\n",
      "ASSISTANT: above:-390;-490;80+35;83;<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(tokr.batch_decode(res)[0].replace(\"*\",\"\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
